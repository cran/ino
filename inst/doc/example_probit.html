<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Example: Probit Model</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Example: Probit Model</h1>



<p>The probit model is a widely employed statistical tool for analyzing
discrete choice behavior in various fields, including transportation
<span class="citation">(<a href="#ref-Bolduc:1999" role="doc-biblioref">Bolduc 1999</a>; <a href="#ref-Shin:2015" role="doc-biblioref">Shin et al. 2015</a>)</span> and marketing <span class="citation">(<a href="#ref-Allenby:1998" role="doc-biblioref">Allenby and Rossi 1998</a>; <a href="#ref-Haaijer:1998" role="doc-biblioref">Haaijer et al. 1998</a>;
<a href="#ref-Paap:2000" role="doc-biblioref">Paap and Franses
2000</a>)</span>. The estimation of probit model parameters typically
involves the numerical maximization of the likelihood function. However,
this approach can be computationally expensive and may encounter
problems in reaching the global optimum, especially when dealing with
complex models. In this vignette, we utilize the <code>{ino}</code>
package to investigate the influence of initialization on the numerical
maximization of the probit likelihood function.</p>
<div id="model-formulation" class="section level2">
<h2>Model formulation</h2>
<p>In our model formulation, we consider a scenario where a total of
<span class="math inline">\(N\)</span> deciders are faced with choosing
among <span class="math inline">\(J \geq 2\)</span> alternatives at each
of the <span class="math inline">\(T\)</span> choice occasions. The
choice made by decider <span class="math inline">\(n\)</span> at
occasion <span class="math inline">\(t\)</span> is denoted as <span class="math inline">\(y_{nt}\)</span> and can take values in the set
<span class="math inline">\(\{1, \dots, J\}\)</span>. For more
comprehensive details on the probit model and its estimation, please
refer to the works by <span class="citation">Train (<a href="#ref-Train:2009" role="doc-biblioref">2009</a>)</span> and <span class="citation">Bhat (<a href="#ref-Bhat:2011" role="doc-biblioref">2011</a>)</span>.</p>
<p>We assume that the choices are rational, meaning that the selected
alternative <span class="math inline">\(y_{nt}\)</span> corresponds to
the alternative with the highest utility among the available options.
The utility for decider <span class="math inline">\(n\)</span> at
occasion <span class="math inline">\(t\)</span> is represented by a
vector <span class="math inline">\(U_{nt} \in \mathbb{R}^J\)</span>,
where each entry of the vector corresponds to the utility associated
with a specific alternative. The probit model explains the utility
vector as <span class="math display">\[U_{nt} = X_{nt} b +
\epsilon_{nt},\]</span> where <span class="math inline">\(X_{nt}\)</span> is a <span class="math inline">\(J\times P\)</span> matrix containing <span class="math inline">\(P\)</span> characteristics for each alternative,
<span class="math inline">\(b\)</span> is a coefficient vector of length
<span class="math inline">\(P\)</span>, and <span class="math inline">\(\epsilon_{nt} \sim N(0,\Sigma)\)</span> denotes
the vector of jointly normally distributed errors, which capture
unobserved influences on the utility.</p>
<p>The probit model (like any utility model) is invariant to the level
and scale of the utilities <span class="math inline">\(U_{nt}\)</span>.
We ensure identifiability by considering utility differences, which
reduces <span class="math inline">\(\Sigma\)</span> from <span class="math inline">\(J\)</span> to <span class="math inline">\(J-1\)</span> dimensions, and fixing the first
entry of <span class="math inline">\(b\)</span> to <span class="math inline">\(1\)</span>.</p>
<p>To account for preference heterogeneity across decision-makers, the
mixed probit model incorporates decider-specific coefficient vectors as
<span class="math inline">\(\beta_n \sim N(b, \Omega)\)</span>. In the
degenerate case where <span class="math inline">\(\Omega = 0\)</span>,
all decision-makers share the same preferences, and <span class="math inline">\(\beta_n \equiv b\)</span>.</p>
<p>The goal of the researcher is to estimate the values for <span class="math inline">\(b\)</span>, <span class="math inline">\(\Omega\)</span>, and <span class="math inline">\(\Sigma\)</span> based on a set of observed choice
data. The most common approach for estimation is the maximum likelihood
method. Let <span class="math inline">\(\theta\)</span> represent the
vector of identified parameters, which includes <span class="math inline">\(P-1\)</span> coefficients of <span class="math inline">\(b\)</span>, <span class="math inline">\(P(P+1)/2\)</span> coefficients of <span class="math inline">\(\Omega\)</span>, and <span class="math inline">\(J(J-1)/2\)</span> coefficients of the differenced
matrix <span class="math inline">\(\Sigma\)</span>. To ensure that the
estimates result in proper covariance matrices, the optimization is
performed over the Cholesky factors. It is important to note that the
length of the parameter vector <span class="math inline">\(\theta\)</span> increases quadratically with both
the number of alternatives <span class="math inline">\(J\)</span> and
the number of choice characteristics <span class="math inline">\(P\)</span>, indicating that numerical optimization
becomes computationally demanding for complex models with a high number
of alternatives or choice covariates.</p>
<p>The maximum likelihood estimate <span class="math inline">\(\hat{\theta}\)</span> is obtained by solving <span class="math display">\[\hat{\theta} = \arg \max_\theta \log \sum_{n,t,j}
1(y_{nt} = j) \int 1(j = \arg \max U_{nt}) \phi(\epsilon_{nt}) d
\epsilon_{nt},\]</span> where <span class="math inline">\(1(\cdot)\)</span> denotes the indicator function
and <span class="math inline">\(\phi(\cdot)\)</span> represents the
Gaussian density. The integral part of the equation does not have a
closed-form expression, thus requiring numerical approximation. Here, we
utilize the <code>mvtnorm::GenzBretz()</code> algorithm by <span class="citation">Genz and Bretz (<a href="#ref-Genz:2009" role="doc-biblioref">2009</a>)</span> for this purpose.</p>
</div>
<div id="data-simulation-and-likelihood-computation" class="section level2">
<h2>Data simulation and likelihood computation</h2>
<p>The <code>{ino}</code> package provides the <code>sim_mnp()</code>
function, which enables simulation of choice data from a probit model.
Prior to utilizing this function, it is necessary to define the function
<code>X(n, t)</code>, which generates a matrix representing the choice
characteristics for decision maker <span class="math inline">\(n\)</span> at choice occasion <span class="math inline">\(t\)</span>. The matrix should have dimensions of
<span class="math inline">\(J \times P\)</span>, where <span class="math inline">\(J\)</span> corresponds to the number of available
alternatives, and <span class="math inline">\(P\)</span> indicates the
number of characteristics describing each alternative.</p>
<p>For our simulation, we have a choice setting with <span class="math inline">\(J = 3\)</span> alternatives, characterized by
<span class="math inline">\(P = 2\)</span> attributes. The values in the
first column of <span class="math inline">\(X_{nt}\)</span> are drawn
from a normal distribution <span class="math inline">\(\mathcal{N}(\mu =
10, \sigma = 3)\)</span>, while the values in the second column are
drawn from <span class="math inline">\(\mathcal{N}(\mu = 0, \sigma =
0.3)\)</span>. This design reflects the common situation of observing
choice covariates on different scales.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="cf">function</span>(n, t) {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  J <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cbind</span>(stats<span class="sc">::</span><span class="fu">rnorm</span>(J, <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">3</span>), stats<span class="sc">::</span><span class="fu">rnorm</span>(J, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">0.3</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">X</span>(<span class="at">n =</span> <span class="dv">1</span>, <span class="at">t =</span> <span class="dv">1</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           [,1]        [,2]</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  8.120639  0.47858424</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] 10.550930  0.09885233</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]  7.493114 -0.24614052</span></span></code></pre></div>
<p>We simulate choice data for <span class="math inline">\(N =
100\)</span> deciders at <span class="math inline">\(T = 20\)</span>
choice occasions from the probit model defined by the parameter values
<span class="math inline">\(b = \begin{pmatrix} 1 &amp; -10
\end{pmatrix}^\top\)</span>, <span class="math inline">\(\Omega =
\begin{pmatrix} 0.2 &amp; 0.5 \\ 0.5 &amp; 2 \end{pmatrix}\)</span>, and
<span class="math inline">\(\Sigma = \begin{pmatrix} 1 &amp; -0.5 &amp;
0.2 \\ -0.5 &amp; 1 &amp; 0.2 \\ 0.2 &amp; 0.2 &amp; 1
\end{pmatrix}\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>Tp <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">10</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>Omega <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="dv">2</span>), <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">0.2</span>, <span class="sc">-</span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="dv">1</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>probit_data <span class="ot">&lt;-</span> <span class="fu">sim_mnp</span>(N, Tp, <span class="at">J =</span> <span class="dv">3</span>, <span class="at">P =</span> <span class="dv">2</span>, b, Omega, Sigma, X, <span class="at">seed =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>The <code>probit_data</code> object is a <code>data.frame</code> with
the decider index <code>n</code>, the choice occasion index
<code>t</code>, the choice <code>y</code>, and the choice
characteristics <code>X</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(probit_data)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   n t y      X.11      X.21      X.31          X.12       X.22        X.32</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 1 1 2 11.228206 15.066620 14.759765 -0.0992723402 -0.6855707  0.74929848</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 1 2 1 11.530325  9.506873 11.262084 -0.1200740232 -0.4110624  0.29635148</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 1 3 2 11.926724  9.865873  4.800345  0.0006395579 -0.1890901 -0.10229057</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 1 4 2  5.183460 10.591580 10.789527 -0.2957480101 -0.8666762 -0.19214451</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 1 5 1 11.682462  6.440624 13.290331 -0.0016032085  0.2121932  0.31023232</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 1 6 3  3.999505  8.365628  9.232988 -0.0498363110  0.3061392  0.04086657</span></span></code></pre></div>
<p>The <code>probit_data</code> object includes the attribute
<code>true</code>, which contains the true and <em>identified</em>
parameter values. These values consist of the mean effects <span class="math inline">\(b\)</span>, excluding the first element, the
elements <span class="math inline">\(o\)</span> of the lower-triangular
Cholesky root of <span class="math inline">\(\Omega\)</span>, and the
elements <span class="math inline">\(l\)</span> of the lower-triangular
Cholesky root of the differenced covariance matrix <span class="math inline">\(\Sigma\)</span> (with respect to alternative <span class="math inline">\(J\)</span>):</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(theta <span class="ot">&lt;-</span> <span class="fu">attr</span>(probit_data, <span class="st">&quot;true&quot;</span>), <span class="dv">2</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    b.2   o.11   o.21   o.22   l.11   l.21   l.22 </span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -10.00   0.45   1.12   0.87   1.26   0.08   1.26</span></span></code></pre></div>
<p>The probit likelihood function is implemented as
<code>f_ll_mnp()</code> and can be evaluated by providing a parameter
vector <code>theta</code> and a data set <code>probit_data</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">f_ll_mnp</span>(<span class="at">theta =</span> theta, <span class="at">data =</span> probit_data)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -696.4395</span></span></code></pre></div>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>To analyze the outcome of the numerical likelihood optimization for
the multinomial mixed probit model, we apply the <code>{ino}</code>
package:</p>
<ul>
<li>We first define a <code>Nop</code> object by setting the target
function <code>f = f_ll_mnp</code>, the number of parameters to
<code>npar = 7</code>, and <code>data = probit_data</code>.</li>
<li>Then, we apply the <code>stats::nlm</code> optimizer with a limit of
1000 iterations. Since this optimizer minimizes the objective function
instead of maximizing it, we set <code>neg = TRUE</code> to compute the
negative log-likelihood value.</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>probit_ino <span class="ot">&lt;-</span> Nop<span class="sc">$</span><span class="fu">new</span>(<span class="at">f =</span> f_ll_mnp, <span class="at">npar =</span> <span class="dv">7</span>, <span class="at">data =</span> probit_data, <span class="at">neg =</span> <span class="cn">TRUE</span>)<span class="sc">$</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_optimizer</span>(<span class="fu">optimizer_nlm</span>(<span class="at">iterlim =</span> <span class="dv">1000</span>))</span></code></pre></div>
<p>The true parameter vector <code>theta</code> is saved to assess the
convergence of the optimization runs to the global optimum:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>probit_ino<span class="sc">$</span>true_parameter <span class="ot">&lt;-</span> theta</span></code></pre></div>
<p>The initial <code>Nop</code> object looks as follows:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(probit_ino)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Optimization problem:</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - Function: f_ll_mnp</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - Optimize over: theta (length 7) </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - Additional arguments: data, neg </span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - True optimum at: -10 0.45 1.12 0.87 1.26 0.08 1.26 </span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - True optimum value: 696.44 </span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Numerical optimizer:</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - 1: stats::nlm </span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Optimization results:</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - Total runs (comparable): 400 (200)</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - Best parameter: -10.49 -0.28 -2.81 0 1.37 0.04 -1.12</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - Best value: 687.71</span></span></code></pre></div>
</div>
<div id="random-initialization" class="section level2">
<h2>Random initialization</h2>
<p>As a benchmark, we optimize <code>runs = 100</code> times using
random initial values drawn from a standard normal distribution:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>probit_ino<span class="sc">$</span><span class="fu">optimize</span>(<span class="at">initial =</span> <span class="st">&quot;random&quot;</span>, <span class="at">runs =</span> <span class="dv">100</span>, <span class="at">label =</span> <span class="st">&quot;random&quot;</span>)</span></code></pre></div>
</div>
<div id="initializing-using-estimates-from-a-data-subsample" class="section level2">
<h2>Initializing using estimates from a data subsample</h2>
<p>Next, we obtain starting values by estimating a probit model on a
subset of the data. In this example, we randomly select 20% of the data
points for the subset. Our aim is to initialize the full model close to
its global optimum by investing a small computational effort in
estimating the reduced model:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>probit_ino<span class="sc">$</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">reduce</span>(<span class="st">&quot;data&quot;</span>, <span class="at">how =</span> <span class="st">&quot;random&quot;</span>, <span class="at">proportion =</span> <span class="fl">0.2</span>)<span class="sc">$</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">optimize</span>(<span class="at">initial =</span> <span class="st">&quot;random&quot;</span>, <span class="at">runs =</span> <span class="dv">100</span>, <span class="at">label =</span> <span class="st">&quot;subset&quot;</span>)<span class="sc">$</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">reset_argument</span>(<span class="st">&quot;data&quot;</span>)<span class="sc">$</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">continue</span>()</span></code></pre></div>
<p>The <code>$reduce()</code> method offers additional options for
selecting the composition of the subset, which can further enhance the
initialization process:</p>
<ul>
<li><p><code>how = &quot;first&quot;</code> and <code>how = &quot;last&quot;</code>: These
options allow to select the subset from the beginning or the end of the
data, respectively, focusing on specific segments of the data
set.</p></li>
<li><p><code>how = &quot;similar&quot;</code> and <code>how = &quot;dissimilar&quot;</code>:
These options utilize k-means clustering to identify subsets of similar
or dissimilar data points. By clustering the data based on similarity, a
subset that represents a distinct group within the data set can be
selected. This approach can be particularly useful when there are
distinct patterns or characteristics within the data.</p></li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>probit_ino<span class="sc">$</span><span class="fu">deviation</span>(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">reference =</span> probit_ino<span class="sc">$</span>true_parameter, <span class="at">which_run =</span> <span class="fu">c</span>(<span class="st">&quot;random&quot;</span>, <span class="st">&quot;subset&quot;</span>),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">parameter_labels =</span> <span class="fu">c</span>(<span class="st">&quot;b.2&quot;</span>, <span class="st">&quot;o.11&quot;</span>, <span class="st">&quot;o.21&quot;</span>, <span class="st">&quot;o.22&quot;</span>, <span class="st">&quot;l.11&quot;</span>, <span class="st">&quot;l.21&quot;</span>, <span class="st">&quot;l.22&quot;</span>),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="estimation-with-standardized-covariates" class="section level2">
<h2>Estimation with standardized covariates</h2>
<p>In choice settings, covariates can have varying scales, which can
result in differences in the magnitudes of model parameters. To enhance
numerical stability during estimation, a common strategy is to
standardize the covariates prior to the estimation. Here, we evaluate
the effectiveness of standardizing covariates using the
<code>$standardize()</code> method. By setting
<code>ignore = 1:3</code>, we exclude the first columns containing
indices from the standardization.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>probit_ino<span class="sc">$</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">standardize</span>(<span class="st">&quot;data&quot;</span>, <span class="at">by_column =</span> <span class="cn">TRUE</span>, <span class="at">ignore =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">optimize</span>(<span class="at">initial =</span> <span class="st">&quot;random&quot;</span>, <span class="at">runs =</span> <span class="dv">100</span>, <span class="at">label =</span> <span class="st">&quot;standardized&quot;</span>)<span class="sc">$</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">reset_argument</span>(<span class="st">&quot;data&quot;</span>)</span></code></pre></div>
<p>We also combine standardization and subsampling:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>probit_ino<span class="sc">$</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">standardize</span>(<span class="st">&quot;data&quot;</span>, <span class="at">by_column =</span> <span class="cn">TRUE</span>, <span class="at">ignore =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">reduce</span>(<span class="st">&quot;data&quot;</span>, <span class="at">how =</span> <span class="st">&quot;random&quot;</span>, <span class="at">proportion =</span> <span class="fl">0.2</span>)<span class="sc">$</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">optimize</span>(<span class="at">initial =</span> <span class="st">&quot;random&quot;</span>, <span class="at">runs =</span> <span class="dv">100</span>, <span class="at">label =</span> <span class="st">&quot;standardized_subset&quot;</span>)<span class="sc">$</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">reset_argument</span>(<span class="st">&quot;data&quot;</span>)<span class="sc">$</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">standardize</span>(<span class="st">&quot;data&quot;</span>, <span class="at">by_column =</span> <span class="cn">TRUE</span>, <span class="at">ignore =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">continue</span>()</span></code></pre></div>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>Both the subset and standardize approach improve the optimization
time significantly in comparison to the random initialization. The
combination of both strategies is twice as fast on average.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(probit_ino, <span class="at">by =</span> <span class="st">&quot;label&quot;</span>, <span class="at">relative =</span> <span class="cn">TRUE</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">3</span>))</span></code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAwAAAAJACAMAAAANcPFkAAABHVBMVEUAAAAAADoAAGYAOjoAOmYAOpAAZrYzMzM6AAA6ADo6AGY6OgA6ZmY6ZpA6kLY6kNtNTU1NTW5NTY5Nbo5NbqtNjshmAABmADpmOgBmOmZmkLZmkNtmtttmtv9uTU1uTW5uTY5ubo5ubqtuq6tuq+SOTU2OTW6OTY6Obk2Ojo6OyP+QOgCQZjqQZmaQkDqQkGaQkLaQtpCQttuQ27aQ29uQ2/+rbk2rbm6rjk2rq46ryKur5P+2ZgC2Zjq2kDq2kGa2tpC2ttu225C22/+2/9u2///Ijk3Ijm7I/8jI///bkDrbtmbb29vb/7bb/9vb///kq27k/8jk///r6+v/tmb/yI7/25D/27b/29v/5Kv//7b//8j//9v//+T///+AmnZ9AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAa3ElEQVR4nO2dC38bN3ZHKe/Glr27Fe3YSh+R43jl2Eu3TdOtnbRSu9um5kZKG6teSVm95vt/jAKYB4YCJeNKQxC8OOcXiSQI/Hk5wpnBDBNmVAEUzGjZBQAsEwSAokEAKBoEgKJBACgaBICiQQAoGgSAoslCgPM//Go0+sXfvp9tPf6bd9X5608utYYt13S+gn8fje6+v3SviY7OAB3kIMDPfz1y/PL7meb9OwIB5neez6F5rbuX7rXRCFAYGQhw/nr0GzP1f/770ezcs3M6Gknnw9FWcK8uBAGKIwMB9kcb/s7p5sbh+uiXb6wWo9GGnY/H6xs/rq/9XWXaf/PezdLD+ohhJu+PZu1knvKd6+OJPZaYR3/8lX2ypX1i1/StdfH3HKEAwUs3iV2VsOosX4Dz1+0cPN385P3p5q/XzbRce9MXwDatfbPu1iszAuw3d3oCHNpuZnwtRa2Jo3tCJMDsS7eJXZWpNhIsiuULcLrZrcJ377w73TRnpef/YVfm7bL+eH30efWjmeBmPvoZejiy9+98b2dpr7OZpJ/bY4m7Z85v99s1vn9CsAS6/NJtYq9KWG3yE8BNQHOvJ8Dd+ujQn6HH6/Wu+3/++A/rs7a4tF17CLE9unT/hEiA2ZduE3tVwmqTnwDu0b6Zp35Ob7S9dtsZerrplh/HblkzK4Cb0odWANvx/HUnQPuESIDwpW1ir0pYbZYvwOVzgCgBdt3MNSuRX//Tf/7vJgLATVm+AJevAtWTbGYJFMzCZkg9qWfOAfpLoEsC3GgJdJUAXZWw2mQgwMznAGan/lftSbC7lDNPgMPm7NNM6vf26qZVouncPwmeEeCGJ8FXCdBVCatNBgJUp71Pgk83f7HeXJzc958DzM7Cn5rLkaPPmzvumBBeBp0RwD8xiABdlbDa5CBA/98FMrPNfupk/6UI48Xdn64VYMt9tvXP9mJM29lMWv9B2IwA3RPDnAO0VcJqk4UAPXrXhDJmNaqECBDgJqxGlRBB8QI0HyX0/sWGsCUAAdSAAAhQNLkJAJAUBICiQQAoGgSAokEAKBoEgKLJXIA/Ly5nlIykb2uJMSuZU6wA8+blYpjzSpnNlMzKQQDPAgUYKDkCBMg4BwEWDwJknIMAiwcBMs5BgMWDABnnIMDiQYCMc0oXwH3J3Fbw7CzH99+Yf67vc3jn3VV9ECDjnMIF2K2/6uojX4gbKcBVTyFAxjllC7Bfz/zz1xvXjkYAvTlFC3D+uln8HN75b+fA/p139htwzVw+fvCP5sb9tzEbPQGO79svyt2w7Vvuq1ZG9SFktPZ1vQTqRnyz3i2tECDjnKIF6Hbr5s6++wLQDfctEvvdF5JuOSl6Aqy7r2Cxv6wrdd/TTfuFXq5bN2K97tK9VKq3tcyYlcxBAIuZt273ff/NYb1H33JfOveX91W7/ukE2Gp/+b7utvakG9F06V4q1dtaZsxK5iCA5fSzN/Y8wOzNm//jwEbz1KH7L4P7S6A3/lfb151JHD+orwJ1IxBgJXKKFqB3DvCuOvzkp9oB1+Imr/sO6tkjwIwATd+eAL0RCLASOUUL0K7S3VWg08++efDOfXu0pd6b25l9eOURoO3rlkD15wC9EQiwEjllCzDzOcCu/a7b+vtFmxlsZ/jx+pUCtH3r/2VGLYAfgQArkVO4AP1PgusvCrWXNutlTOX+J2Jrv3cnyPMEaPv2L4P6EQiwEjmlC5ACBMg4BwEWDwJknIMAiwcBMs4pVwD+m+ChY1Yyp1gB0n0rRNq3tcSYlcwpV4CbMNTWyuxtZVYOAngy26QIoC4HASQggLocBJCAAOpy1ApwbxGM7K+lvq2F5GRWDgJ4biGAfMTHh4xuFByS2UzJrBwE8CBAipzMykEADwKkyMmsHATwIECKnMzKQQAPAqTIyawcBPAgQIqczMpBAA8CpMjJrBwE8CBAipzMykEADwKkyMmsHATwIECKnMzKQQAPAqTIyawcBPAgQIqczMpBAA8CpMjJrBwE8CBAipzMykEADwKkyMmsHATwIECKnMzKQQAPAqTIyawcBPAgQIqczMpBAA8CpMjJrBwE8CBAipzMykEADwKkyMmsHATwIECKnMzKQQAPAqTIyawcBPAgQIqczMpBAA8CpMjJrBwE8CBAipzMykEADwKkyMmsHATwIECKnMzKQQAPAqTIyawcBPAgQIqczMpBAA8CpMjJrBwE8CBAipzMykEADwKkyMmsHATwIECKnMzKQQAPAqTIyawcBPAgQIqczMpBAA8CpMjJrBwE8CBAipzMykEADwKkyMmsHATwIECKnMzKWaYAJ8/2wj4Xbydhy5yeYb+G6Zz2ua8UgAApcjIrZzUEmJOFALFkNlMyK2c5AhyNx4/2zl6YXydPx+NJdfL8O3tTmaZPX5mHdeOXr1wn02Im8HQ8Hj+p3JiuXz/NTXL7M/2di6ob6wHNqCHewnwQIHnMSua0Apy93KsOntjpevbVjr05ebpdHT3+UE3NzXjSNZp5XLe4PfjFtzv2oRnYtAZptQCPP9jgurEZ0B0B/hzLPRnizRUrwFKJ3lpwPYEAZoZX3cLEzNVm8tpZ2yxtmsamxfU82HYDTVOv32yaE8BqM2kamwEsgfLJyayc5SyBzBrn4U4twNQuVZrJWzdMZhtti7v7/INd0IzNyK7f5TT786cd91zd2B8wyFuYDwIkj1nJnP5J8FG9UnkxaWe+PwL0Gv0RwC6A3MOqqmaPAD6tPQI0z5nGZgAC5JOTWTlLEcAu9+sp62btFzvd5O1W/E2jbzELoKp+2J0rzKbZ1c6BOdeduiV/09gMQIB8cjIrZzlHALfEMTvqR3sH4+YqjxPg4q27uuMbm5aTZz/Ytcx42yxpzMKm7TeTZkf99qW7CmS7TLurQOaRfaVh3sJ8ECB5zErm8EmwH4EABeYMK4D9tMCd4g4ViAApcjIrZ4UFGBwESJGTWTkI4EGAFDmZlYMAHgRIkZNZOQjgQYAUOZmVgwAeBEiRk1k5COBBgBQ5mZWDAB4ESJGTWTkI4EGAFDmZlYMAHgRIkZNZOQjgQYAUOZmVgwAeBEiRk1k5COBBgBQ5mZWDAB4ESJGTWTkI4EGAFDmZlYMAHgRIkZNZOQjgQYAUOZmVgwAeBEiRk1k5COBBgBQ5mZWDAB4ESJGTWTkI4EGAFDmZlYMAHgRIkZNZOQjgQYAUOZmVgwAeBEiRk1k5COBBgBQ5mZWDAB4ESJGTWTkI4EGAFDmZlYMAHgRIkZNZOQjgQYAUOZmVgwAeBEiRk1k5COBBgBQ5mZWDAB4ESJGTWTkI4EGAFDmZlYMAHgRIkZNZOQjgQYAUOZmVgwAeBEiRk1k5COBBgBQ5mZWDAB4ESJGTWTkI4LmFAItgdC/CkoW+rYXkZFYOAngy26RDba3M3lZm5SCAJ7NNigDqchBAAgKoy0EACQigLgcBJCCAuhwEkIAA6nIQQAICqMtBAAkIoC4HASQggLocBJCAAOpyEEACAqjLQQAJCKAuBwEkIIC6HASQgADqchBAAgKoy0EACQigLgcBJCCAuhwEkIAA6nIQQAICqMtBAAkIoC4HASQggLocBJCAAOpyEEACAqjLQQAJCKAuBwEkIIC6HASQgADqchBAAgKoy0EACQigLgcBJCCAupxiBBjs26FvzaBvK6eYlcwpR4D4zld/BfoQWwsBsspBgBAEKCgHAUIQoKAcBAhBgIJyECAEAQrKQYAQBCgoBwFCEKCgHAQIQYCCchAgBAEKykGAEAQoKAcBQhCgoBwECEGAgnIQIAQBCspBgBAEKCgHAUIQoKAcBAhBgIJyECAEAQrKQYAQBCgoBwFCEKCgHAQIQYCCchAgBAEKykGAEAQoKAcBQhCgoBwECEGAgnIQIAQBCspBgBAEKCgHAUIQoKAcBAhBgIJyECAEAQrKQYAQBCgoBwFCEKCgHAQIQYCCchAgBAEKykGAEAQoKAcBQhCgoBwECEGAgnIQIAQBCspBgBAEKCgHAUIQoKAcBAhBgIJybvMnPXm2FzZevJ2ELXN6hv3mgQDXggC3zkkjwJzBCDAAeQpw7+oNKMq5NYsT4Gg8frR39sL8Onk6Hk+qk+ff2ZvKNH36yjysG7985TqZFqPKdDweP6ncmK7fMG8hBgRIENPk3Lt3WwOyF+Ds5V518MQeAc6+2rE3J0+3q6PHH6qpuRlPukYzxesWd6y4+HbHPjQDm9amygjuDUD821uwADr4yB8r5q+6VG71J7UzvOqWQEYHe8/qYMRoljZNY9Pieh5su4GmqdfvI3AEuBaOALfOudmf1KxxHu7UAkztaqgRoG6YzDbaFnf3+Qe79BmbkV2/Qd5CDAiQIKagcwCDWfHYff6LSTvz/RGg1+iPAHYB5B5WVcURYICcariczMrJXwC73K8FcDP/i512Z+9X/E2jbzELoKp+2J0rDPQWYkCABDErmXOzP6lb4pid+KO9g3FzlccJcPHWXd3xjU3LybMf7OJnvG3WQGbt1PYb5i3EgAAJYlYyh0+CQxCgoBwECEGAgnIQIAQBCspBgBAEKCgHAUIQoKAcBAhBgIJyECAEAQrKQYAQBCgoBwFCEKCgHAQIQYCCchAgBAEKykGAEAQoKAcBQhCgoBwECEGAgnIQIAQBCspBgBAEKCgHAUIQoKAcBAhBgIJyECAEAQrKQYAQBCgoBwFCEKCgHAQIQYCCchAgBAEKykGAEAQoKAcBQhCgoBwECEGAgnIQIAQBCspBgBAEKCgHAUIQoKAcBAhBgIJyECAEAQrKQYAQBCgoBwFCEKCgHAQIQYCCchAgBAEKykGAEAQoKAcBQhCgoBwECEGAgnIQIAQBCsopR4AhGA2QMezbyilmJXOKEWAQhtpamb2tzMpBAE9mmxQB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF1OqQIs78txb8ZCN88qTtyhcooV4EYx12+tq79W/dYgwKJyEEACAqjLQQAJCKAuBwEkIIC6HASQgADqchBAAgKoy0EACQigLgcBJCCAuhwEkIAA6nIQQAICqMtBAAkIoC4HASQggLocBJCAAOpyEEACAqjLQQAJCKAuBwEkIIC6HASQgADqchBAAgKoy0EACQigLgcBJCCAuhwEkIAA6nIQQAICqMtBAAkIoC4HASQggLocBJCAAOpyEEACAqjLQQAJCKAuBwEkIIC6HASQgADqchBAAgKoy0EACQigLgcBJCCAuhwEkIAA6nIQQAICqMtBAAkIoC4HASQggLocBJCAAOpyEEACAqjLQQAJCKAuBwEkIIC6HASQgADqcpIIMJ2EbSfP9iJGIkATPb8ZAW6dgwASEEBdzoIEOBqPH+25SW5/pr8bjydtY3X2wty4Xx/PQYAmen4zAtw6ZzECnL3cqw6eeAEefzA3TWM13W6fq6uUcm8QbvS+lieAFsR/7UUR9ye9KWdf7dibToCJXQY1jfbGuMASSAJHgEXlLGgJdPJ0/HCnE+BPO+48oG40i5+xuUUACQiwqJzFnQQfuXVPewS4eDtpGu1KqOIkWAYCLCpnMQKYee7mulntHJhz3alb8jeN9hygkePjIEATPb8ZAW6ds6AjwLS+4HMwHv/2pbsK9HCnazRrIPPo4i1XgeJBgEXl8EmwBARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXU6xAtyI0c2G3Z7Fbp5VnLhD5ZQqwM0Yamtl9rYyKwcBPJltUgRQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUgQAxL/3boSwz0tgaOWckcBIihnXHDba1b/b8EEGC4HASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDanEQCXLyd3GhcJpsUAdTmIEAMCKA2Z3ABTr589Wjv5Ol4PKlOnn9nb6qzF+NPX03szaO96uLbfx2Pt4/MT0xaJpsUAdTmDC/AUzPVv9qpTp4ZDbaro8cfqqm5MSJM3aOLt09Mnyf2+abKW3IvBYNvrdsJoIrbToCb0W7L4QVoJvbZyz171/yYe3YJZG+MGRff7lT2x0rycTLZp+QmQHuHI8CtcxYkwHRsljuNAK5lOrE3ZuYjQJ2IAHnkLESAsxeTduZzBLgiEQHyyFmIAO7ni5327uw5AAK4RATII2cxS6CDsb3u0wpw8XbmKhACVAiQTQ6fBMeAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEAMCqM1BgBgQQG0OAsSAAGpzECAGBFCbgwAxIIDaHASIAQHU5iBADAigNgcBYkAAtTkIEMO9htG9LBjqbQ0cs5I5CCBhqK2V2dvKrBwE8GS2SRFAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXQ4CSEAAdTkIIAEB1OUggAQEUJeDABIQQF0OAkhAAHU5CCABAdTlIIAEBFCXgwASEEBdDgJIQAB1OQggAQHU5SCABARQl4MAEhBAXU7mAgAsFgSAokEAKBoEgKJBACgaBICiQQAoGgSAokEAKJocBTh5tldVZy/Gjz90N1P7++LtZEkV5VFFS1bb5+TpeDzJp5zqaDx+JNk8GQpwZN+BrfbgSXtz8vzDdLs6erKkivKooiWr7XP21U518sVOLuW4nYMvJKKe/ASYPvw38ybOXu7ZN9PcmNoPti++3VlSSXlU4crIaPu4ctysmk4yKKfZPFXVKySinvwEqC020tq9i7+Zbh8sbdebRxXdXziT7dNNuJk6lrehunrqfX5kPbkKcPTYld7c2EXc/7384cV4eykFZVGFWdwa7EtnsX18ORdvt5dfjq/n5OnDHUE9WQkwHY+tpuEezj55sH2w3dxNTR5VXHMEWEplTTlnL7arHMq55oh0XT1ZCdBwEqxxK/f2ppMlLcDzqGJGgAy2T13OydNJVeVQjhcgOCe5rp5cBbDHVXca724qa3C1tH1vHlV05LR96vmfTTnt2ie+nlwFuHQhtz7GLuscIJMqWnLaPgdu6T3JpRxXkDkHiK8nRwEAkoEAUDQIAEWDAFA0CABFgwBQNAgwAOevR44N33R8/013/+fvZx5e4vDOu0stcWOvibxq5Lwh1xR3fd1KQIABOH/tpv7x+lbX1Js5H5lEoQA9bj4BI0de003/5LcgwAA0AlS7d7smBFgREGAA+gLY5ZCZ0nb2HK/bZZH9vXF8/19cn/0775oOjtPN0drX5kHddt50+a/LY9+4DnftnPzGtNTHGdPcf+i7fD0affK+HVl3cUFbbsi6W6xtffwF5iZU/epVgAAD0AhwaGbI+WszjfbNBLz/5nRzy81458L9N6bRdmw72AGnmxvmx878uq3pEo61HezP8brpsV9PQDeb/UPfpc5rRtZdRnW/Zp9un457gSChX70OEGAA2pPgrWZBY2aXmTl/sdPE7ULf9G7aDnacu2+mVW9Q0/PSWNfB/HJnGc00dnPTP7zcpZu+W83JSdNm2DUTOO4FgoR+9TpAgAFwR4DjdbeAaa4HuUl0aO6tvel2shtuL9+7YOR2pccP3rVtTZdw7KHr2MzgngC9hzNdZmRqunQCNDv4mBcIEvaDy12rDgIMQL0EsiugbnngljFr/V2/maI/1RO8G9cJ0LbVXcKxQwpwuGb7x71AKICm1Y8DAQagOQfYNbvWenpV3aQ67Hay1eln3zzwHSztwqNrq7uEY12Hw2YRf4UAbRe3WHnw7ioBmteKe4EgoV+9DhBgALrPAeyZpJlZ9cSyk+V4fc2d0LoJtDtyV4nqDnbA6ebd5iS4bdutL8VcHtudo14twOWT4GbkZQHazyoiXmBeQr96HSDAALSXQffN4tieENerCzObR2u/N7PIzOpmWb9VVW0HR/8yqGtzXeaM7a5SXinAzGVQ+3lEPfKyALtuDb8W8wLzEmaqVwECKKOdvRAHAigDAWQggDIQQAYCQNEgABQNAkDRIAAUDQJA0SAAFA0CQNH8Py4s5s5T1biqAAAAAElFTkSuQmCC" width="75%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;dplyr&quot;</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(probit_ino, <span class="at">which_element =</span> <span class="fu">c</span>(<span class="st">&quot;seconds&quot;</span>, <span class="st">&quot;label&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(label) <span class="sc">%&gt;%</span> </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean_seconds =</span> <span class="fu">mean</span>(seconds, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd_seconds =</span> <span class="fu">sd</span>(seconds, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(mean_seconds)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 3</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   label               mean_seconds sd_seconds</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                      &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 standardized_subset        1038.       548.</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 standardized               1442.       995.</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 subset                     1747.      1024.</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 random                     2177.      1589.</span></span></code></pre></div>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Allenby:1998" class="csl-entry">
Allenby, G. M., and P. E. Rossi. 1998. <span>“Marketing Models of
Consumer Heterogeneity.”</span> <em>Journal of Econometrics</em> 89 (1):
57–78.
</div>
<div id="ref-Bhat:2011" class="csl-entry">
Bhat, C. 2011. <span>“The Maximum Approximate Composite Marginal
Likelihood (MACML) Estimation of Multinomial Probit-Based Unordered
Response Choice Models.”</span> <em>Transportation Research Part B:
Methodological</em> 45.
</div>
<div id="ref-Bolduc:1999" class="csl-entry">
Bolduc, D. 1999. <span>“A Practical Technique to Estimate Multinomial
Probit Models in Transportation.”</span> <em>Transportation Research
Part B: Methodological</em> 33 (1): 63–79.
</div>
<div id="ref-Genz:2009" class="csl-entry">
Genz, Alan, and Frank Bretz. 2009. <em>Computation of Multivariate
Normal and t Probabilities</em>. Vol. 195. Springer Science &amp;
Business Media.
</div>
<div id="ref-Haaijer:1998" class="csl-entry">
Haaijer, R., M. Wedel, M. Vriens, and T. Wansbeek. 1998. <span>“Utility
Covariances and Context Effects in Conjoint MNP Models.”</span>
<em>Marketing Science</em> 17 (3): 236–52.
</div>
<div id="ref-Paap:2000" class="csl-entry">
Paap, R., and P. H. Franses. 2000. <span>“A Dynamic Multinomial Probit
Model for Brand Choice with Different Long-Run and Short-Run Effects of
Marketing-Mix Variables.”</span> <em>Journal of Applied
Econometrics</em> 15 (6): 717–44.
</div>
<div id="ref-Shin:2015" class="csl-entry">
Shin, J., C. R. Bhat, D. You, V. M. Garikapati, and R. M. Pendyala.
2015. <span>“Consumer Preferences and Willingness to Pay for Advanced
Vehicle Technology Options and Fuel Types.”</span> <em>Transportation
Research Part C: Emerging Technologies</em> 60.
</div>
<div id="ref-Train:2009" class="csl-entry">
Train, K. 2009. <em>Discrete Choice Methods with Simulation</em>. 2. ed.
Cambridge Univ. Press.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
